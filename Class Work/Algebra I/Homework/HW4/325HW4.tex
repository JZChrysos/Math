\documentclass{amsart}

\input{C:/Users/jzchr/MathDocuments/preamble_general.tex}
\usepackage{quiver}

\title{Math 325 HW 4}
\author{Jalen Chrysos}

\begin{document}
	\textbf{Problem 1}: Let $M_n=M_n(\C)$ and let 
	$$
	\det(\lambda I - a) = \lambda^n + s_1(a)\lambda^{n-1} + \cdots + s_{n-1}(a)\lambda + s_n(a)
	$$
	where $a\in M_n$. Note that $s_i\in \C[M_n]$. Let $G=\GL_n(\C)$ act on $M_n$ by conjugation. For $g\in G$, 
	$$
	\det(\lambda I - gag^{-1}) = \det(\lambda I - a)
	$$
	so $s_i\in \C[M_n]^G$ for all $i$. Show that $\C[M_n]^G$ is a free polynomial algebra with generators $s_1,\dots,s_n$. \\
	
	\begin{proof}
		$G$-invariant polynomials are determined by their values on $G$-orbits, i.e. the conjugacy classes of matrices. If $p\in \C[M_n]^G$, $p$ is determined by its values on inputs $a_{ij}$ that are diagonalizable as matrices (since this is a dense subset of $\C^{n^2}$). And on such inputs, by $G$-invariance, $p$ is determined by its value on the conjugate diagonal matrix. Thus, $p$ is determined by the values it takes on all diagonal matrices.\\
		
		Now, if $a$ is a diagonal matrix, we get
		$$
		\det(\lambda I - a) = (\lambda - a_{11})(\lambda - a_{22})\cdots (\lambda - a_{nn}),
		$$
		so $s_i$ take the values of the elementary symmetric polynomials on $a_{11},\dots,a_{nn}$. And we know that the space of all symmetric polynomials on $n$ variables is generated as a free algebra by the elementary symmetric polynomials. Thus, there is some algebraic combination of $s_1,\dots,s_n$ which matches $p$ on the diagonal matrices, and thus (because of $G$-invariance and the density of the diagonalizable matrices) on all inputs in $\C^{n^2}$. That is, all of $\C[M_n]^G$ is generated as an algebra by $s_1,\dots,s_n$.
	\end{proof}
	
	\newpage 
	
	\textbf{Problem 2}: Let $M = \bigoplus_{i\geq 0} M_i$ be a graded $A$-module ($A$ is itself a graded $k$-algebra), let $\{m_s\in M, s\in S\}$ be a collection of homogeneous elements and $\overline{m_s}$ the image of $m_s$ under the projection $M\to M/A_{>0}M$.
	\begin{enumerate}[(a)]
		\item Show that $m_s$ generate $M$ as an $A$-module iff the elements $\overline{m_s}$ span $M/A_{>0}M$ as a $k$-vector space. 
		\item Deduce that $M$ is finitely generated iff the $k$-vector space $M/A_{>0}M$ has finite dimension.
	\end{enumerate}
	\begin{proof}
		(a): In one direction, if $m_s$ span $M$ then clearly $\overline{m_s}$ span $M/A_{>0}M$, as the projection is surjective. Everything in $M/A_{>0}M$ exists in $M$ as a $k$-linear combination in $M$.\\
		
		In the other direction, suppose $\overline{m_s}$ span $M/A_{>0}M$. Let $M'$ be the $A$-submodule of $M$ generated by $m_s$. We will show that $M_i\subseteq M'$ for each $i$, inductively. For $M_0$ this is clear, as $M_0$ is fixed by the projection. Now assume that $M_i\subseteq M'$ for a given $i$ and we will show that the same is true for $M_{i+1}$. Each $m\in M_{i+1}$ can be written as
		$$
		a_{i+1}m_0 + a_im_1 + a_{i-1}m_2 + \cdots + a_0m_{i+1}
		$$
		where $a_j\in A_j$ and $m_j\in M_j/A_{>0}M$. Then we have $\overline{m}\equiv a_0m_{i+1}$. We assumed that this was in the span of $\overline{m_s}$, and by inductive hypothesis all of the other components are in $M'$, so $m\in M'$ as well. Thus the induction is complete and $M'=M$.\\
		
		(b): By part (a), if $M$ is finitely-generated by $m_s$, then $M/A_{>0}M$ is spanned over $k$ by $\overline{m_s}$.\\
		
		Conversely, if $M/A_{>0}M$ is finite-dimensional with basis $m_0,m_1,\dots,m_n\subset M_N$, then $M$ is generated over $A$ by these same elements by (a), as they project down to themselves.
	\end{proof}
	
	\newpage
	\textbf{Problem 3}: Let $R= \{a_s \in A_{>0}, s\in S\}$ be a collection of homogeneous elements.
	\begin{enumerate}[(a)]
		\item Prove that $A_{>0}$ is generated by $R$ as an ideal iff $A$ is generated by $R$ as an algebra.
		\item Deduce that $A_{>0}$ is finitely-generated as an ideal iff $A$ is finitely-generated as an algebra.
	\end{enumerate}
	
	\begin{proof}
		(a): Suppose $A_{>0}$ is generated by $R$ as an ideal, and let $A'$ be the graded algebra generated over $k$ by $R$. We will show $A_i\subseteq A'$ for each $i$ inductively. For $A_0$, it is automatic because $k=A_0$. Now assume that $A_{i}\subseteq A'$ and we will show the same for $A_{i+1}$. For each $a\in A_{i+1}$, since $A_{>0}$ is generated by $R$ as an ideal, we have 
		$$
		a = a_1r_1 + a_2r_2 + \cdots + a_nr_n
		$$
		for some $r_j\in R$ and $a_j\in A$. And since everything in $R$ has degree at least 1, all of these $a_j$ are strictly lower in degree than $a$, so they're in $A_i$. By the inductive hypothesis, they are all in $A'$. Thus $a\in A'$ as well. This concludes the induction, showing that $A=A'$.\\
		
		Conversely if $A$ is generated by $R$ as an algebra, then $A=k[R]$, so for any $a\in A_j$ with $j\geq 1$, $a$ can be written as a $k$-linear combination of polynomials of positive degree in $R$, which is also an $A$-linear combination of elements in $R$ (just take all but one of the $R$ terms in each monomial to be the coefficient in $A$), thus $A_{>0}$ is generated by $R$ as an ideal.\\
		
		(b): If $A$ is finitely-generated as an algebra, then there is some finite algebra generator set $R$ (we can assume it is positive-degree because everything in $k$ is already generated in any algebra over $k$). So by (a), $A_{>0}$ is finitely generated as an ideal (by $R$).\\
		
		Conversely if $A_{>0}$ is finitely-generated as an ideal by some $R$, then we can assume $R$ is positive-degree, so part (a) applies. 
	\end{proof}
	
	\newpage
	\textbf{Problem 4}: Let $A$ be a finite-dimensional algebra over an algebraically closed field $k$ and $A_{mod}$ the algebra $A$ viewed as a rank 1 free $A$-module. Thus, a left ideal of $A$ is the same thing as a left $A$-submodule of $A_{mod}$. Show that if the $A$-module $A_{mod}$ is completely reducible then the following holds:
	\begin{enumerate}[(a)]
		\item Any left ideal of $A$ is of the form $Ae$ where $e=e^2 \in A$. 
		\item (Wedderburn theorem) $A$ is isomorphic to $M_{\ell_1}(k)\oplus \cdots \oplus M_{\ell_r}(k)$ for some $\ell_1,\dots,\ell_r\geq 0$.
	\end{enumerate}
	
	\begin{proof}
		(a): Let $I$ be a left ideal of $A$. Then $I$ is also a left $A$-submodule of $A_{mod}$. By complete reducibility we can express $A$ as a direct sum with $I$, $A=I\oplus I'$. Then $1\in A$ can be expressed uniquely as $1=e+e'$ where $e\in I$ and $e'\in I'$.
		
		First, note that 
		$$
		e+e' = 1= \<e+e',e+e'\> = e^2 + e'^2\; \implies \; e=e^2, \; e'=e'^2,
		$$
		using the fact that the decomposition is unique, i.e. this is the only way to express $1$ as an element of $I\oplus I'$. Moreover, $I=Ae$ and $I'=Ae'$; if $b\in I$ then 
		$$b=b(e+e') = be + be'=be$$
		as $b$ has no $I'$ component. Thus $I\subseteq Ae$ and the other direction is trivial, so $I=Ae$.\\
		
%		Left ideals of $A$ correspond with left $A$-submodules of $A_{mod}$. Since we are assuming $A_{mod}$ is completely reducible, we can write it as
%		$$
%		A_{mod} = N_1\oplus N_2\oplus \cdots \oplus N_r
%		$$
%		for some simple $A$-modules $N_j$. Then any left $A$-submodule of $A_{mod}$ is some sum of these.\\
		
		(b): First, because $A_{mod}$ is rank 1 as an $A$-module, $A^{op}\cong \End_A(A_{mod})$ via the map $$
		a\mapsto [b\mapsto ab].
		$$
		Note that $aa'$ acts as scaling by $a'a$ so the order is reversed, hence $A^{op}$. The map is invertible because $A_{mod}$ is 1-dimensional as an $A$-module, hence every automorphism is scaling by something in $A$ (Schur's Lemma).
		
		Now we can show that $\End_A(A_{mod})$ has the desired form; this follows from the fact that $A$ is completely reducible, using problem 8 on the previous homework. Hence $A^{op}$ has the desired form, and also $A$ does as well, using the fact that $M_{\ell}(k)\cong M_{\ell}(k)^{op}$ (such a map can be given by transposition). 
		
	\end{proof}
	
	\newpage
	\textbf{Problem 5}: Let $W$ be a vector subspace of a $k$-vector space $V$.
	\begin{enumerate}[(a)]
		\item Let $f\in \End_k(V)$ with $\im(f)=W$. Show that $f$ is idempotent (i.e. $f^2=f$) iff $f$ projects onto $W$, i.e. $V=W\oplus W'$ and $f(w,w')=(w,0)$.
		\item Define 
		$$I_W := \{f\in \End_k(V) \; | \; \ker(f)\subseteq W \}, \;\;\; J_W := \{f\in \End_k(V) \; | \; \im(f)\subseteq W\}$$
		$I_W$ and $J_W$ are left and right ideals of $\End_k(V)$ respectively. Show that if $V$ is finite-dimensional then all left ideals $I$ are of the form $I_W$ for 
		$$
		W := \bigcap_{f\in I} \ker(f)
		$$
		and similarly every right ideal $J$ is of the form $J_W$ where 
		$$
		W := \Span \{\im(f)\}_{f\in J}
		$$
	\end{enumerate}
	
	\begin{proof}
		(a): If $f$ projects onto $W$ then it is clearly idempotent, as $f^2(w,w') = f(w,0) = (w,0)$. 
		
		Conversely, suppose $f$ is idempotent. $f$ is surjective onto $W$ because $W$ is its image, so for each $w\in W$ let $v$ be such that $f(v)=w$. Then 
		$$f(v)=w \implies w = f(v) = f^2(v) = f(w)$$ 
		by idempotence of $f$, i.e. $f$ fixes $W$. 
		
		Now let $W'=\ker(f)$. I claim $V=W\oplus W'$. First, the two subspaces have intersection $0$, as $0=f(x)=x$ for all $x\in W\cap W'$. And their span is all of $V$: for $v\in V$, suppose $f(v)=w\in W$, and let $w'=v-w$ so that $v=w+w'$. Then $w'\in W'$, as 
		$$f(w')=f(v)-f(w) = w - w = 0.$$
		Thus $f$ is a projection onto $W$.\\
		
		(b): $\End_k(V)$ is completely reducible as a module over itself (in fact, it is a simple module), so we can apply problem 4(a). Since $I$ is a left-ideal, by problem 4(a) it is of the form $\End_k(A)e$ where $e$ is an idempotent matrix, i.e. a projection by 5(a). For this $e$, 
		$$
		W = \bigcap_{f\in I} \ker(f) = \bigcap_{f\in \End_k(V)} \ker(fe) = \ker(e) 
		$$
		as $\ker(fe)\supseteq \ker(e)$ with equality when $f=\id_V$. So $I_W$ is the set of $f$ which vanish on $\ker(e)$, i.e. 
		$$I_W = \{f\in \End_k(V) \; : \; \ker(f)\subseteq \ker(e)\} = \End_k(V)e = I.$$
		
		For right ideals, we have $J=e\End_k(V)$ for some projection $e$. Thus
		$$
		W = \Span\{\im(f)\}_{f\in J} = \Span\{\im(ef)\}_{f\in \End_k(V)} = \im(e)
		$$
		because $\im(ef)\subseteq\im(e)$ with equality when $f=\id_V$. Now,
		$$
		J_W = \{f \in \End_k(V) \; : \; \im(f)\subseteq \im(e)\} = e \End_k(V) = J.
		$$
	\end{proof}
	
	\newpage
	\textbf{Problem 6 (Proposition 6.1.2 in notes)}: 
	\begin{enumerate}[(a)]
		\item Any completely reducible finite-dimensional $A$-module is isomorphic to a finite direct sum of simple modules.
		\item Let $V_1,\dots,V_r$ be distinct irreducible representations over $A$ and 
		$$
		M := (V_1)^{\ell_1} \oplus \cdots \oplus (V_r)^{\ell_r}.
		$$
		Then $M^{(V_i)}=(V_i)^{\ell_i}$ (the isotypic component), and $\ell_i=\dim_k(\Hom_A(V_i,M))$. 
		\item Let $f:M\to N$ be a morphism of finite-dimensional $A$-modules. Then for any irreducible $V$, $f(M^{(V)})\subseteq N^{(V)}$. 
	\end{enumerate}
	\begin{proof}
		(a): We show this by induction on dimension. A 1-dimensional $A$-module is simple. Let $M$ be a completely-reducible finite-dimensional $A$-module. If $M$ is simple then we are done. Otherwise, take some submodule $M_1$. By complete-reducibility $M=M_1\oplus M_2$ for some $M_2$. But now $M_1,M_2$ are lower dimension than $M$, so by inductive hypothesis we can express both $M_1$ and $M_2$ as finite direct sums of simple modules, and hence $M$ can be expressed this way as well.\\
		
		(b): $M^{(V_i)}$ is by definition the direct sum of all submodules of $M$ isomorphic to $V_1$. There are $\ell_1$ copies of $V_1$ in the decomposition given, and this is all of the isomorphic copies of $V_1$; if $V_i$ maps into $M$ then restricting to any $V_j$ with $j\neq i$ we get by Schur's Lemma that the map must be trivial. Thus $\Hom_A(V_i,M)$ consists exactly of the direct sum of identity maps into the $\ell_i$ copies of $V_i$, and thus has dimension $\ell_i$.\\
		
		(c): For every submodule $V'$ of $M$ isomorphic to $V$ (irreducible), $f(V')$ is an irreducible submodule of $N$. By Schur's Lemma it is either isomorphic to $V$ or $0$. Thus, every such $f(V')$ is contained in $N^{(V)}$. It follows that $f(M^{(V)})\subseteq N^{(V)}$. 
	\end{proof}
\end{document}