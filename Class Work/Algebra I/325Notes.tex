\documentclass{amsart}
\input{C:/Users/jzchr/MathDocuments/preamble_general.tex}

\title{Algebra I Notes}
\author{Jalen Chrysos}

\begin{document}

\maketitle
\begin{abstract}
	These are my notes from Victor Ginzburg's Representation Theory (Math 325) class at UChicago, Autumn 2025.
\end{abstract}

\tableofcontents

\newpage

\section{Introduction}

%Representations arise from actions. Suppose a group $G$ acts on a set $X$. Then $G$ also acts linearly on $\Hom(X,\C)$ (the space of maps $X\to\C$) via 
%$$
%g : f \mapsto g\circ f,
%$$
%hence it is in isomorphism with $\GL(\Hom(X,\C))$. \\

In this class we'll be interested in the representations of matrix groups. Something like $\GL(V)$ or $\SO(V)$ clearly acts on $V$, but it can also act on other interesting spaces. One relevant case of this for us will be when $G$ acts on polynomials in $x_1,\dots,x_n$. Let 
$$
P_d \subseteq \C[x_1,\dots,x_n]
$$
be the subspace of homogeneous degree-$d$ polynomials in $n$ variables. This space has a basis given by the monomials
$$
\big\{x_1^{d_1}x_2^{d_2}\cdots x_n^{d_n} \; | \; \sum_i d_i = d\big\}
$$
and hence is finite-dimensional. $P_d$ is stable under action by $\GL_n$. This is because linear transformation does not affect the degree of monomials (every $x_j$ is sent to a linear combination of $x_1,x_2,\dots,x_n$).\\

Consider the case of $G=\OO_n$, the orthogonal group. This group fixes the polynomial 
$$R:=x_1^2+\dots+x_n^2$$
so as a result, multiplication by $R$ is an intertwining map $P_d\to P_{d+2}$, meaning $R\circ g^*f = g^*(R\circ f)$.

Likewise, let
$$
\Delta := \sum_j \frac{\partial^2}{\partial x_j^2}
$$
be the Laplacian. This $\Delta$ is an $\OO_n$-intertwining operator.

We call a function $f$ \textit{harmonic} if it has $\Delta(f)=0$. The space of harmonic polynomials in $n$ variables of degree $d$ is denoted $H_d\subseteq P_d$. For $d\in \{0,1\}$, $H_d=P_d$, but for $d\geq 2$ $H_d$ is strictly smaller. Note that $H_d$ is stable under orthogonal transformations.\\

We will now work toward showing that $H_d$ is an irreducible $\SO_n$-representation for $n\geq 3$.\\

A representation $\rho:G\mapsto \GL(V)$ is \textit{unitary} if $G$ always acts as a unitary operator (i.e. preserves Hermitian inner product) on $V$. We can give an inner product between polynomials (or any functions) by
$$
\<f_1,f_2\> := \int_{\R^n} f_1(x)\overline{f_2(x)} e^{-|x|^2} \; \d x
$$
where $\d x$ is the Lebesgue measure. Action of $\SO_n$ on $P_d$ preserves this inner product.

Alternatively, we could put an inner product on $P_d$ (or on all functions) from integration over $S^{n-1}$ (the sphere). And polynomials in $P_d$ are determined by their behavior on $S^{n-1}$.\\

\noindent \textbf{Proposition}: If $V$ is a finite-dimensional vector space with an inner product, then any \textit{unitary} action of $G$ on $V$ is completely reducible. Specifically, if $W\subseteq V$ is a $G$-stable subspace, then one can decompose the action into $V=W\oplus W^{\bot}$.
\begin{proof}
	The thing that we need to prove is that if $W$ is $G$-stable then $W^{\bot}$ is as well. Let $x\in W^{\bot}$ and $w\in W$. Because $g$ acts as a \textit{unitary} operator, we have
	$$
	\<g\cdot x,w\> = \<x,g^{-1}\cdot w\> = 0
	$$
	since $g^{-1}\cdot w \in W$ by $G$-stability of $W$.
\end{proof}\\

\noindent \textbf{Key Lemma}: If $F\subseteq C(S^{n-1})$ is any subspace stable under $\SO_n$, then it has an element fixed by $\SO_{n-1}$.
\begin{proof}
	Let $N:=(0,0,\dots,0,1)\in S^{n-1}$. We have the evaluation map $\a:C(S^{n-1})\to \C$ given by evaluating functions at $N$. We have an inner product on $F$ given by 
	$$
	\<f,g\> := \int_{S^{n-1}} f\overline{g}
	$$
	which is clearly fixed by $\SO_n$, thus $F$ is a unitary representation of $\SO_n$. By Riesz representation theorem, $\a(f)\equiv \<f,\ph\>$ for some $\ph\in F$. For any $g\in \SO_{n-1}$, $g$ fixes $N$, thus
	$$
	\<f,\ph\> = f(N) = f(gN) = (g^{-1}f)(N) = \<g^{-1}(f),\ph\> = \<f,g\ph\>
	$$ 
	and because this is true for arbitrary $f\in F$ and $g\in SO_{n-1}$, $\ph$ is fixed by $\SO_n$. Now it remains to show that $\ph\neq 0$. We can get this by assuming that some function in $F$ takes a nonzero value on $N$ (we can move $N$ to some point where this is true, since $F$ contains a nonzero function).
\end{proof}\\

We can apply this key lemma to $P_d$ or $H_d$ as $F$.\\

Consider $P_d^{\SO_{n-1}}$, the homogeneous polynomials fixed by $\SO_{n-1}$. On homework we showed that this is a subspace of $\C\<x_n,R\>$ (where $R:=x_1^2+\dots+x_n^2$). One basis of this space is
$$
P_d^{\SO_{n-1}} := \C\<x_n^d,x_n^{d-2}R,x_n^{d-4}R^2,\dots\>
$$
thus $\dim(P_d^{\SO_{n-1}})=\lfloor \tfrac{d}{2} \rfloor + 1$. 

A very important fact about $P_d$ is that it decomposes into the subspaces
\begin{align*}
P_d &= H_d \oplus R\cdot P_{d-2}\\
&= H_d \oplus R H_{d-2} \oplus R^2 H_{d-4} \oplus R^3H_{d-6} \oplus \cdots 
\end{align*}
(we will show this later). This allows us to deduce the dimension of $H_d$ from $P_d$:
$$
\dim(H_d) = \dim(P_d) - \dim(P_{d-2}) = {d+2 \choose 2} - {d \choose 2} = 2d+1.
$$
Likewise, we can decompose $P_d^{\SO_{n-1}}$ the same way:
\begin{align*}
P_d^{\SO_{n-1}} &= H_d^{\SO_{n-1}} \oplus R P_{d-2}^{\SO_{n-1}} \\
&= H_d^{\SO_{n-1}} \oplus R H_{d-2}^{\SO_{n-1}} \oplus R^2 H_{d-4}^{\SO_{n-1}} \oplus R^3H_{d-6}^{\SO_{n-1}} \oplus \cdots 
\end{align*}
%Because we already know the dimension of $P_d^{\SO_{n-1}}$, we can use this decomposition to see that $\dim(H_{d-2j}^{\SO_{n-1}})=1$ for all $j$; the dimension of each of these spaces is at least one by the Key Lemma, since $H_{d-2j}$ is stable under action of $\SO_n$, and this already hits the total of $\lfloor d/2\rfloor + 1$, so the dimension must be exactly one.
which gives us the dimension of $H_d^{\SO_{n-1}}$ as
$$
\dim(H_d^{\SO_{n-1}}) = \dim(P_d^{\SO_{n-1}}) - \dim(P_{d-2}^{\SO_{n-1}}) = (\lfloor d/2\rfloor + 1) - (\lfloor (d-2)/2\rfloor + 1) = 1.
$$
As a consequence, we see that each $H_d$ is an \textit{irreducible} representation of $\SO_n$; every stable subspace has a fixed point by the Key Lemma, and the fixed-points are one-dimensional, so there can only be one stable subspace. Thus, as an $\SO_n$-representation, $P_d$ decomposes exactly into the sequence $H_{d-2j}$ for $2j\leq d$.\\

\noindent \textbf{Theorem}: If $n\geq 3$, then for each $d\geq 0$, the representation of $\SO_n$ in $H_d$ is irreducible, and moreover the representations are all distinct for different $d$.\footnote{In the case $n=3$ this gives \textit{all} the irreps. In general you miss $\Lambda^2(\C^n)$, but when $n=3$ this is just $\C^3$, which you get from $H_1$.}

\begin{proof}
	To show that the representations are distinct, we can use a homework problem which shows that the dimension of $H_d$ is always increasing in $d$ for any $n\geq 3$.
\end{proof}\\

\subsection{Differential Algebra}

Let $W$ be a vector space over $k$ with basis $w_1,\dots,w_n$, and let $x_1,\dots,x_n$ be a dual basis for $W^*$. We let
$$
k[W] := \bigoplus_{d\geq 0} k[W]_d
$$
be the homogeneous polynomials over $W$, where 
$$
k[W]_j := \Sym^j(W^*).
$$
We have the directional derivative operator
$$
\partial_{\xi} : k[W]_j \to k[W]_{j-1}
$$
which acts on $k[W]$ in the expected way (product rule). Thus we have the differential algebra
$$
\D(W) = k[\partial_{w_1},\dots,\partial_{w_n}]
$$
acting on $k[W]$. There is a natural correspondence between $k[W]$ and $\D(W)$, if one assumes that $k$ is characteristic 0. We have a $k$-bilinear pairing 
$$
\D(W) \times k[W] \to k
$$
by $\<u,f\>\mapsto u(f)(0)$. This is a \textit{perfect pairing}. And in general we can do the same thing with 
$$
\Sym^j(W)\times \Sym^j(W^*)\to k.
$$

\noindent \textbf{Lemma}: Let $\xi\in W$ and $f\in k[W]$. Then
$$\<\xi^m,f\> = m!f(\xi).$$
In particular, if $f=\ph\in W^*$, $\<\xi^m,\ph^m\>=m!\ph^m(\xi)$.
\begin{proof}
	We will show this for homogeneous $f$ first, and the general result will follow from expressing $f$ as a sum of homogeneous polynomials. Let the degree of $f$ be $d$. Then by Taylor expansion,
	$$f(\xi) = \sum_{k\geq 0} \frac{1}{k!}(\partial_{\xi}^kf)(0).$$
	But note that only the $d$th term of this is nonzero, since $\partial^j_{\xi}f= 0$ unless $j=d$ (since we are evaluating at $0$). Thus,
	$$
	f(\xi) = \frac{(\partial^d_{\xi}f)(0)}{d!}
	$$
	and for other $j$ both sides are 0.
\end{proof}\\

We can use this pairing to get another inner product on polynomials in $k[W]$ given by
$$
\<p,q\> := p(\partial)(q)(0)
$$
where $p(\partial)$ is the corresponding element to $p$ in $\D(W)$.\footnote{In the homework, we establish that on $H_d$, this is actually \textit{equivalent} to the inner product from integrating over $S^{n-1}$!} For this inner product, we have that multiplication by $p$ is \textit{adjoint} to $p(\partial)$, i.e.
$$
\<r,p(\partial)q\> = \<pr,q\>.
$$
With this fact, we can finally show why $P_d = H_d \oplus R P_{d-2}$:
$$
W = \ker(\Delta) \oplus \im(\Delta^*) = \ker(\Delta) \oplus \im(R) = H_d \oplus R P_{d-2}.
$$

Another application of this pairing:
Let $V$ be a finite dimensional vector space and $A\subseteq V$ a subset of $V$ (not necessarily subspace).
Let $\Span^d(A)\subseteq \Sym^d(V)$ be generated over $\C$ by $a^d$ for $a\in A$.
If $A$ is dense in $V$ then $\Span^d(A) = \Sym^d(A)$. 
We will show this by using the pairing.

Assume for contradiction that $\Span^d(A)\neq \Sym^d(V)$. 
Then there is some nonzero linear functional $F:\Sym^d(V)\to \C$ which vanishes on $\Span^d(A)$. 
Then $F$ corresponds to some differential polynomial $f$, and $\partial^d_a f(0) = 0$ for all $a\in A$.
But $\partial^d_af(0) = d!f(a)$, so $f(a)=0$. But then $A$ is dense, so $f=0$.\\

\subsection{Representation Theory Basics}
 
If $G$ acts on sets $X$ and $Y$, then $G$ can also act on the space of maps $X\to Y$ via conjugation:
$$
g: f \mapsto g\circ f \circ g^{-1}.
$$
We can ask about the space of maps which commute with this $G$-action. Or, equivalently, the maps which are fixed by the $G$-action. 
We call these \textit{intertwining operators}. 
The set of such operators is denoted $\Hom_G(X,Y)$. 

We are usually interested in the case where $X,Y$ are vector spaces and $\Hom(X,Y)$ is the space of linear maps.\\

\noindent \textbf{Schur-Weyl Duality}: 
Let $W$ be a finite-dimensional vector space over $\C$.
$\GL(W)$ can act on $W^{\otimes d}$ with $g$ acting as $g^{\otimes d}$.
$S_d$ also acts on $W^{\otimes d}$ by permutation.
It is not too hard to see that these two actions commute.
But moreover, action by $\GL(W)$ \textit{spans} the space of $S_d$-intertwiners on $W^{\otimes d}$.

\begin{proof}
	Let $\Phi:(\End(W))^{\otimes d}\to \End(W^{\otimes d})$ be given by
	$$
	\Phi: a_1\otimes \cdots \otimes a_d \mapsto \big(w_1\otimes \cdots \otimes w_d \mapsto a_1(w_1)\otimes \cdots \otimes a_d(w_d)\big).
	$$
	$\Phi$ is an invertible linear map with inverse
	$$
	\Phi^{-1} f \mapsto f|_{W_1}\otimes \cdots \otimes f|_{W_d}
	$$ 
	where $W_j$ is $0 \otimes \cdots \otimes W \otimes \cdots \otimes 0$ with the $W$ in the $j$th spot.
	Note also that $\Phi$ commutes with the action of $S_d$. By using $\Phi$, we see that 
	$$
	\Sym^d(\End W) = ((\End W)^{\otimes d})^{S_d} \xrightarrow{\Phi^{-1}} \End_{S_d}(W^{\otimes d}).
	$$
	So we only need to understand $\Sym^d(\End W)$. But $\GL(W)$ is dense in $\End(W)$, so by a previous lemma, we see that $\Span^d(\GL(W))=\Sym^d(\End W)$.
\end{proof}\\

\subsection{Spectral Theorem}

Let $A$ be a $k$-algebra with $a\in A$. We have an evaluation map
$$
\ev_a : k[t] \to A \;\;\; \ev_a: p\mapsto p(a).
$$
Let $A_a:= \im(\ev_a)$, i.e. the subalgebra of $A$ generated by $a$. The kernel $\ker(\ev_a)$ is an ideal of $k[t]$, and it is a principal ideal since $k[t]$ is a PID. Thus, in the case that $\ev_a$ is non-injective, there is a unique \textit{minimal polynomial} of $a$, $p_a$, which divides every polynomial which vanishes at $a$.\\

\noindent \textbf{Lemma}: $a$ is algebraic iff $A_a$ is finite-dimensional.
\begin{proof}
	If $A_a$ is finite-dimensional then there is a relation between $1,a,a^2,\dots,a^n$ for some $n$, i.e. a polynomial that $a$ solves. Conversely if $a$ solves a polynomial of degree $n$ then every linear combination of powers of $a$ can be expressed by the first $n$ powers of $a$.
\end{proof}\\

We define the \textit{spectrum} of $a$, denoted $\Spec(a)$, as
$$
\Spec(a) := \{\lambda \in k : (a-\lambda) \text{ is not invertible}\}.
$$
So for example, if $A$ is a function algebra, $\Spec(a)$ denotes the values that $a$ can take. In the case that $A$ is the matrix algebra $M_n(k)$, $\Spec(a)$ is the set of eigenvalues of $a$.\\

\textbf{The Spectral Theorem}: Let $A$ be a $k$-algebra of one of the following types:
\begin{itemize}
	\item $A$ is finite-dimensional over $k$ and $k$ is algebraically closed.
	\item $A$ is countable-dimension and $k$ is uncountable.
\end{itemize}
Then,
\begin{enumerate}[(i)]
	\item $\Spec(a)$ is nonempty.
	\item $a$ is nilpotent iff $\Spec(a)=\{0\}$.
	\item If $A$ is a division algebra then $A=k$.\footnote{For a counterexample of this when $k$ is not algebraically closed, take the Quaternions over $\R$.}
\end{enumerate}
\begin{proof}
	Lemma: If $\lambda_1,\dots\lambda_n\not\in \Spec(a)$, i.e. $(a-\lambda_j)$ is invertible for each $j$, then if 
	$$
	\sum_j c_j(a-\lambda_j)^{-1} = 0
	$$
	for some $c_j\in k$ then $a$ is algebraic (proof is by clearing denominators). We will use this fact.\\
	
	(i): We will split into two cases: if $a$ is algebraic then $\Spec(a)$ is finite but nonempty and if $a$ is not algebraic then $\Spec(a)$ is uncountable (and the converses to both of these are true).
	
	If $a$ is algebraic, then $\Spec(a)$ is the roots of the minimal polynomial (HW), and particular this means $\Spec(a)$ is finite and nonempty because $k$ is algebraically closed.
	
	If $a$ is not algebraic, then by the Lemma, there is no linear relation between any finitely-many $(a-\lambda)^{-1}$ for $\lambda\not\in \Spec(a)$. We assumed that $\dim(A)$ is at most countable, and it has an independent set of size $|k\setminus \Spec(a)|$, so $\Spec(a)$ must be uncountable (because $k$ is).\\
	
	(ii): If $a^n=0$, then $0\in \Spec(a)$ because $a$ is not invertible, but all other $(a-\lambda)$ are invertible:
	$$
	(a-\lambda)(a^{n-1}+a^{n-2}\lambda + a^{n-3}\lambda^2 + \dots + \lambda^{n-1}) = a^n-\lambda^n = -\lambda^n.
	$$
	so
	$$
	(a-\lambda)^{-1} = -\lambda^{-n}(a^{n-1}+a^{n-2}\lambda + a^{n-3}\lambda^2 + \dots + \lambda^{n-1}).
	$$
	Conversely, suppose that $\Spec(a)=\{0\}$. $\{0\}$ is a finite set, so by part (i), $a$ is algebraic, but its minimal polynomial only has root $a=0$, so $a^n=0$ for some $n$.
	\\
	
	(iii): Assume for contradiction that $A$ is a division algebra yet $\exists a\in A\setminus k$. Then $(a-\lambda)$ is invertible for all $\lambda \in k$, but then $\Spec(a)$ would be empty, contradicting (i).
\end{proof}\\

\subsection{Modules}

A module $M$ over ring $A$ is called \textit{simple} if it is nonzero and has no proper nontrivial submodules (i.e. its only submodules are $0$ and $M$).\\

\noindent \textbf{Schur's Lemma}: If $f:M\to N$ is an $A$-linear map between \textit{simple} $A$-modules $M$ and $N$, then $f$ is either $0$ or an isomorphism.
\begin{proof}
	$\ker(f)$ is a submodule of $M$ and $\im(f)$ is a submodule of $N$. By simplicity, both must be either trivial or the full module. This implies that $f$ is either injective or 0, and either surjective or 0.
\end{proof}\\

As a corollary, we see that $\End_AM$ is a division ring.\\

\noindent \textbf{Schur's Lemma for Algebras}: If $A$ is a $k$-algebra and $M$ a simple $A$-module either 
\begin{itemize}
	\item $k$ is algebraically closed and either $A$ or $M$ is finite-dimensional over $k$.
	\item $k=\C$ and either $A$ or $M$ is countable-dimension over $k$.
\end{itemize}
Then, $\End_AM = k \id_M$.
\begin{proof}
	On HW we showed that $\dim(\End_AM) \leq \dim_A M$. The lemma can be proven by applying the spectral theorem to the algebra $\End_AM$.
\end{proof} \\

If $A$ satisfies the hypotheses of the Spectral Theorem and $M$ is a simple $A$-module, then the center $Z$ of $A$ acts in $M$ by scalars, as $z\cdot am = az\cdot m$ for $z\in Z, a\in A, m\in M$. And in particular if $A$ is commutative then $\dim_k M=1$ because every subspace of $M$ is $A$-stable.\\

\noindent \textbf{Schur's Lemma for Group Representations}: If $V,W$ are representations of a group $G$ over a field $k$,
\begin{enumerate}[(i)]
	\item If $V,W$ are irreducible then all intertwiners are either 0 or isomorphisms.
	\item If $\dim_k(V)$ is finite and $k$ is algebraically closed or $k=\C$ and $|G|=\aleph_0$, then 
	$$
	\End_GV= k\cdot \id_V.
	$$
\end{enumerate}
\begin{proof}
	This follows from applying Schur's Lemma for Algebras. A representation of $G$ corresponds to a module over the group algebra $A:= kG$. Note that $\dim_k(A) = |G|$.
\end{proof}\\

\subsection{Representations of $S_n$} $S_n$ acts on $\R^n$ by permuting the coordinates. We have the sign representation given by taking the determinant.\\

$S_n$ also acts on $P_d$ by permuting the variables:
$$
\sigma(f)(x_1,\dots,x_n) := f(x_{\sigma^{-1}(1)},x_{\sigma^{-1}(2)},\dots,x_{\sigma^{-1}(n)}).
$$
Motivated by this action, we can consider the symmetric polynomials $P^{S_n}$.\\

A \textit{partition} of $n$ is a finite non-increasing sequence of positive integers $\lambda_1\geq \dots \geq \lambda_k$ whose sum is $n$. Let the set of partitions of $n$ be $\PP_n$. Corresponding to a partition, we have a decomposition of $[1,n]$ into $I_1,I_2,\dots,I_k$ of length $|I_j|=\lambda_j$.\\

The \textit{Vandermonde Determinant} is the polynomial
$$
\Delta_n := \prod_{1\leq i < j \leq n} (x_j-x_i)
$$
which can also be written as the determinant 
$$
\det \begin{pmatrix}
	1 & 1 & \dots & 1\\
	x_1 & x_2 & \dots & x_n \\
	x_1^2 & x_2^2 & \dots & x_n^2\\
	\vdots & \vdots & \ddots & \vdots \\
	x_1^{n-1} & x_2^{n-1} & \dots & x_n^{n-1}
\end{pmatrix}
$$
Corresponding to a given partition $\lambda$, define
$$
\Delta(I_m) := \prod_{i<j \in I_m} (x_j-x_i)
$$
and 
$$
\Delta_{\lambda} := \prod_m \Delta(I_m).
$$
$\Delta_{\lambda}$ is a homogeneous polynomial, and its degree is 
$$
d := \sum_{m} \frac{\lambda_m(\lambda_m-1)}{2}
$$
so $\Delta_{\lambda}\in P_d$.\\ 

The \textit{Specht Module} associated with $\lambda$, denoted $V(\lambda)$ is the $k$-span of $\Delta_{\lambda}$ under the action of $S_n$. It is clearly stable under the action of $S_n$.\footnote{This is not the most common way to construct the Specht module of $\lambda$.}\\

Examples:
\begin{itemize}
	\item Let $\lambda = (1,1,1,\dots,1)$. Then $\Delta_{\lambda} = 1$,  and $V(\lambda) = P_0$, the constant polynomials. The action of $S_n$ on $V(\lambda)$ is trivial. Thus, this $\lambda$ represents the trivial representation.
	\item Let $\lambda = (n)$. Then $\Delta_{\lambda} = \Delta_n$, the entire Vandermonde determinant. Since this is just a determinant whose columns are permuted by the action of $S_n$, the action scales by the sign of the permutation. This makes $V(\lambda) = k\Delta_n$, which is one-dimensional. It is the sign representation of $S_n$.
\end{itemize}
Note that in all of these cases $V(\lambda)$ is irreducible. This is actually true in general:\\

\textbf{Theorem}: Assuming that the underlying field $k$ is characteristic 0, the Specht module is always an irreducible representation. Moreover, all irreps of $S_n$ can be expressed as $V(\lambda)$ for some partition $\lambda$.\footnote{It is also true that $V(\lambda)$ is a subspace of the $S_n$-harmonic polynomials (as defined on HW) and the index is $\dim(V(\lambda))$.}

\begin{proof}
	The proof has three steps. The first step will be to show that $V(\lambda)$ is irreducible, which we do on homework. Step 2 is that the number of irreducible representations of $S_n$ is equal to the number of partitions of $n$. Step 3 will show that the modules $V(\lambda)$ are pairwise non-isomorphic for different $\lambda$, and hence we have a bijection.\\
	
	Step 3: In homework (it is fairly clear I think) we showed that if $d_{\mu}\neq d_{\lambda}$ then $V(\mu)\not\cong V(\lambda)$, so it remains to show this for $\mu,\lambda$ that have equal degree.
	
	Notation: for $\nu \in \Z_{\geq 0}^n$ (note: may have repeats!), $S_n$ acts on $\nu$ in the natural way. Let $m_j(\nu)$ denote the number of elements of $\nu$ that are equal to $j$ (this is invariant under $S_n$). Let $\nu(\lambda)$ be 
	$$
	\nu(\lambda) := (1,2,\dots,\lambda_1,1,2,\dots,\lambda_2,\dots ,1,2,\dots,\lambda_n).
	$$
	Then $m_j(\nu(\lambda))$ is the length of the $j$th column in the Young diagram of $\lambda$, $D(\lambda)$. Or equivalently, the $m_j$ form another partition corresponding to the transposed Young diagram $D^T(\lambda)$.
	
	Similarly, we can apply all this to polynomials in $n$ variables. The monomial $x^{\nu}$ is
	$$
	x^{\nu} := \prod_{j=1}^nx_j^{\nu_j}
	$$
	so that for a partition $\lambda$,
	$$
	x^{\nu(\lambda)} := \prod_{i=1}^k \prod_{j=1}^{\lambda_i} x_{\lambda_i + j}^{j}.
	$$
	Recall that $\Delta_{\lambda}$ is defined in terms of Vandermonde determinants, which are expressed as
	$$
	\Delta_n = \sum_{\sigma \in S_n} \sgn(\sigma) x_1^{\sigma(1)-1}\cdots x_n^{\sigma(n)-1}.
	$$
	And for $\Delta_{\lambda}$, we have a similar thing but with Young subgroups:
	$$
	\Delta_{\lambda} = \sum_{\sigma \in S_{\lambda}} \sgn(\sigma) x_1^{\sigma(1)-1} \cdots x_n^{\sigma(n)-1} =  \frac{1}{x_1x_2\cdots x_n} \sum_{\sigma \in S_{\lambda}} \sgn(\sigma) x^{s(\nu(\lambda))}. 
	$$
	Now, if $V(\mu)=V(\lambda)$, then $\Delta_{\mu}\in V(\lambda)$, i.e. it is a linear combination of permutations of $\Delta_{\lambda}$. So for example, the monomial $x^{\nu(\mu)}$ appears as $x^{\sigma(\nu(\lambda))}$ for some $\sigma$. But we can show that this fails (\textit{fill in later}).
\end{proof}\\

The \textit{Young Subgroup} of $S_n$ corresponding to $\lambda$ consists of all permutations which preserve all the pieces $I_m$. It is denoted $S_{\lambda}$ and is isomorphic to $S_{\lambda_1}\times S_{\lambda_2} \times \dots \times S_{\lambda_k}$.

Define $P^{S_{\lambda}}$ to be the polynomials fixed by $S_{\lambda}$, and $P^{\sgn(\lambda)}$ the polynomials on which $S_{\lambda}$ acts in an anti-symmetric way. We can see that $P^{\sgn(\lambda)}$ is stable under scaling by $P^{S_{\lambda}}$, i.e. it is a $P^{S_{\lambda}}$-submodule.\\

\textbf{Lemma}: Let $F:V(\lambda)\to P_d$ be an $S_n$-intertwiner. Then
\begin{enumerate}
	\item If $d=d_{\lambda}$, then $F$ acts by scaling.
	\item If $d<d_{\lambda}$, then $F$ is trivial.
\end{enumerate}
\begin{proof}
	For $s\in S_{\lambda}$, $s(F(\Delta_{\lambda})) = F(s(\Delta_{\lambda}))$, and $s(\Delta_{\lambda}) = \sgn_{\lambda}(s)\cdot \Delta_{\lambda}$, so $F$ acts by scaling. \textit{fill in later}
\end{proof}\\

In general, we can see that $V(\lambda^t) = V(\lambda)\otimes \sgn$.\\

\subsection{Hilbert's Nullstellensatz} 
Let $k$ be an algebraically closed field and let $P=k[x_1,\dots,x_n]$. An \textit{algebraic} subset of $k^n$ is the vanishing set of an ideal $I\subset P$, denoted $V(I)$. In the other direction, we have an ideal $I_V$ corresponding to polynomials vanishing on a given algebraic set $V$.\\

For any ideal $I\subset P$, there is a \textit{radical} of $I$, denoted $\sqrt{I}$, which consists of all elements of $P$ for which some power lies in $I$. Note that $V(I)=V(\sqrt{I})$. Moreover, ideals of the form $I_V$ are already radical. The interesting thing is that the correspondence goes both ways:\\

\textbf{Nullstellensatz}: Algebraic sets are in bijection with \textit{radical} ideals of $P$, via $V \mapsto I_V$ and $V(I) \mapsfrom I$. This bijection restricts to one between single points of $k^n$ and maximal ideals of $P$.
\begin{proof}
	We will show that $I_{V(I)}=\sqrt{I}$, the content of which is that every polynomial $f$ vanishing on $V(I)$ has $f^n\in I$ for some $n$.\\
	
	Lemma: for $z\in k^n$, let $\ev_z:P\to k$ be the algebra homomorphism given by evaluation at $z$, i.e. $\ev_z: f\mapsto f(z)$. In fact, \textit{every} algebra homomorphism $\chi: P\to k$ is $\ev_z$ for some $z$. In particular, take $z=(\chi(x_1),\chi(x_2),\dots,\chi(x_n))$ and note that $\chi(f) = \ev_z(f).$\\
	
	Now, let $A$ be a commutative $k$-algebra as in the setting of the Spectral theorem (i.e. finite-dimensional or countable dimension with uncountable $k$). We claim that all maximal ideals of $A$ have the form $\ker(\chi)$ for some algebra homomorphism $\chi: A \to k$, and moreover $\Spec(a)$ is exactly $\{\chi(a) : \chi\in \Hom(A,k)\}$.
	
	To prove the first statement: let $I\subset A$ be a maximal ideal. This implies that $A/I$ is a field, and in particular a division algebra, so the spectral theorem implies that $A/I=k$. Thus the projection onto $I$ gives a character $A\to A/I=k$.
	
	
\end{proof}


\end{document}