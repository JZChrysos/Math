\documentclass{amsart}
\input{C:/Users/jzchr/MathDocuments/preamble_general.tex}

\title{Algebra I Notes}
\author{Jalen Chrysos}

\begin{document}

\maketitle
\begin{abstract}
	These are my notes from Victor Ginzburg's Representation Theory (Math 325) class at UChicago, Autumn 2025.
\end{abstract}

\tableofcontents

\newpage

\section{Introduction}

%Representations arise from actions. Suppose a group $G$ acts on a set $X$. Then $G$ also acts linearly on $\Hom(X,\C)$ (the space of maps $X\to\C$) via 
%$$
%g : f \mapsto g\circ f,
%$$
%hence it is in isomorphism with $\GL(\Hom(X,\C))$. \\

In this class we'll be interested in the representations of matrix groups. Something like $\GL(V)$ or $\SO(V)$ clearly acts on $V$, but it can also act on other interesting spaces. One relevant case of this for us will be when $G$ acts on polynomials in $x_1,\dots,x_n$. Let 
$$
P_d \subseteq \C[x_1,\dots,x_n]
$$
be the subspace of homogeneous degree-$d$ polynomials in $n$ variables. This space has a basis given by the monomials
$$
\big\{x_1^{d_1}x_2^{d_2}\cdots x_n^{d_n} \; | \; \sum_i d_i = d\big\}
$$
and hence is finite-dimensional. $P_d$ is stable under action by $\GL_n$. This is because linear transformation does not affect the degree of monomials (every $x_j$ is sent to a linear combination of $x_1,x_2,\dots,x_n$).\\

Consider the case of $G=\OO_n$, the orthogonal group. This group fixes the polynomial 
$$R:=x_1^2+\dots+x_n^2$$
so as a result, multiplication by $R$ is an intertwining map $P_d\to P_{d+2}$, meaning $R\circ g^*f = g^*(R\circ f)$.

Likewise, let
$$
\Delta := \sum_j \frac{\partial^2}{\partial x_j^2}
$$
be the Laplacian. This $\Delta$ is an $\OO_n$-intertwining operator.

We call a function $f$ \textit{harmonic} if it has $\Delta(f)=0$. The space of harmonic polynomials in $n$ variables of degree $d$ is denoted $H_d\subseteq P_d$. For $d\in \{0,1\}$, $H_d=P_d$, but for $d\geq 2$ $H_d$ is strictly smaller. Note that $H_d$ is stable under orthogonal transformations.\\

We will now work toward showing that $H_d$ is an irreducible $\SO_n$-representation for $n\geq 3$.\\

A representation $\rho:G\mapsto \GL(V)$ is \textit{unitary} if $G$ always acts as a unitary operator (i.e. preserves Hermitian inner product) on $V$. We can give an inner product between polynomials (or any functions) by
$$
\<f_1,f_2\> := \int_{\R^n} f_1(x)\overline{f_2(x)} e^{-|x|^2} \; \d x
$$
where $\d x$ is the Lebesgue measure. Action of $\SO_n$ on $P_d$ preserves this inner product.

Alternatively, we could put an inner product on $P_d$ (or on all functions) from integration over $S^{n-1}$ (the sphere). And polynomials in $P_d$ are determined by their behavior on $S^{n-1}$.\\

\noindent \textbf{Proposition}: If $V$ is a finite-dimensional vector space with an inner product, then any \textit{unitary} action of $G$ on $V$ is completely reducible. Specifically, if $W\subseteq V$ is a $G$-stable subspace, then one can decompose the action into $V=W\oplus W^{\bot}$.
\begin{proof}
	The thing that we need to prove is that if $W$ is $G$-stable then $W^{\bot}$ is as well. Let $x\in W^{\bot}$ and $w\in W$. Because $g$ acts as a \textit{unitary} operator, we have
	$$
	\<g\cdot x,w\> = \<x,g^{-1}\cdot w\> = 0
	$$
	since $g^{-1}\cdot w \in W$ by $G$-stability of $W$.
\end{proof}\\

\noindent \textbf{Key Lemma}: If $F\subseteq C(S^{n-1})$ is any subspace stable under $\SO_n$, then it has an element fixed by $\SO_{n-1}$.
\begin{proof}
	Let $N:=(0,0,\dots,0,1)\in S^{n-1}$. We have the evaluation map $\a:C(S^{n-1})\to \C$ given by evaluating functions at $N$. We have an inner product on $F$ given by 
	$$
	\<f,g\> := \int_{S^{n-1}} f\overline{g}
	$$
	which is clearly fixed by $\SO_n$, thus $F$ is a unitary representation of $\SO_n$. By Riesz representation theorem, $\a(f)\equiv \<f,\ph\>$ for some $\ph\in F$. For any $g\in \SO_{n-1}$, $g$ fixes $N$, thus
	$$
	\<f,\ph\> = f(N) = f(gN) = (g^{-1}f)(N) = \<g^{-1}(f),\ph\> = \<f,g\ph\>
	$$ 
	and because this is true for arbitrary $f\in F$ and $g\in SO_{n-1}$, $\ph$ is fixed by $\SO_n$. Now it remains to show that $\ph\neq 0$. We can get this by assuming that some function in $F$ takes a nonzero value on $N$ (we can move $N$ to some point where this is true, since $F$ contains a nonzero function).
\end{proof}\\

We can apply this key lemma to $P_d$ or $H_d$ as $F$.\\

Consider $P_d^{\SO_{n-1}}$, the homogeneous polynomials fixed by $\SO_{n-1}$. On homework we showed that this is a subspace of $\C\<x_n,R\>$ (where $R:=x_1^2+\dots+x_n^2$). One basis of this space is
$$
P_d^{\SO_{n-1}} := \C\<x_n^d,x_n^{d-2}R,x_n^{d-4}R^2,\dots\>
$$
thus $\dim(P_d^{\SO_{n-1}})=\lfloor \tfrac{d}{2} \rfloor + 1$. 

A very important fact about $P_d$ is that it decomposes into the subspaces
\begin{align*}
P_d &= H_d \oplus R\cdot P_{d-2}\\
&= H_d \oplus R H_{d-2} \oplus R^2 H_{d-4} \oplus R^3H_{d-6} \oplus \cdots 
\end{align*}
(we will show this later). This allows us to deduce the dimension of $H_d$ from $P_d$:
$$
\dim(H_d) = \dim(P_d) - \dim(P_{d-2}) = {d+2 \choose 2} - {d \choose 2} = 2d+1.
$$
Likewise, we can decompose $P_d^{\SO_{n-1}}$ the same way:
\begin{align*}
P_d^{\SO_{n-1}} &= H_d^{\SO_{n-1}} \oplus R P_{d-2}^{\SO_{n-1}} \\
&= H_d^{\SO_{n-1}} \oplus R H_{d-2}^{\SO_{n-1}} \oplus R^2 H_{d-4}^{\SO_{n-1}} \oplus R^3H_{d-6}^{\SO_{n-1}} \oplus \cdots 
\end{align*}
%Because we already know the dimension of $P_d^{\SO_{n-1}}$, we can use this decomposition to see that $\dim(H_{d-2j}^{\SO_{n-1}})=1$ for all $j$; the dimension of each of these spaces is at least one by the Key Lemma, since $H_{d-2j}$ is stable under action of $\SO_n$, and this already hits the total of $\lfloor d/2\rfloor + 1$, so the dimension must be exactly one.
which gives us the dimension of $H_d^{\SO_{n-1}}$ as
$$
\dim(H_d^{\SO_{n-1}}) = \dim(P_d^{\SO_{n-1}}) - \dim(P_{d-2}^{\SO_{n-1}}) = (\lfloor d/2\rfloor + 1) - (\lfloor (d-2)/2\rfloor + 1) = 1.
$$
As a consequence, we see that each $H_d$ is an \textit{irreducible} representation of $\SO_n$; every stable subspace has a fixed point by the Key Lemma, and the fixed-points are one-dimensional, so there can only be one stable subspace. Thus, as an $\SO_n$-representation, $P_d$ decomposes exactly into the sequence $H_{d-2j}$ for $2j\leq d$.\\

\noindent \textbf{Theorem}: If $n\geq 3$, then for each $d\geq 0$, the representation of $\SO_n$ in $H_d$ is irreducible, and moreover the representations are all distinct for different $d$.\footnote{In the case $n=3$ this gives \textit{all} the irreps. In general you miss $\Lambda^2(\C^n)$, but when $n=3$ this is just $\C^3$, which you get from $H_1$.}

\begin{proof}
	To show that the representations are distinct, we can use a homework problem which shows that the dimension of $H_d$ is always increasing in $d$ for any $n\geq 3$.
\end{proof}\\

\subsection{Differential Algebra}

Let $W$ be a vector space over $k$ with basis $w_1,\dots,w_n$, and let $x_1,\dots,x_n$ be a dual basis for $W^*$. We let
$$
k[W] := \bigoplus_{d\geq 0} k[W]_d
$$
be the homogeneous polynomials over $W$, where 
$$
k[W]_j := \Sym^j(W^*).
$$
We have the directional derivative operator
$$
\partial_{\xi} : k[W]_j \to k[W]_{j-1}
$$
which acts on $k[W]$ in the expected way (product rule). Thus we have the differential algebra
$$
\D(W) = k[\partial_{w_1},\dots,\partial_{w_n}]
$$
acting on $k[W]$. There is a natural correspondence between $k[W]$ and $\D(W)$, if one assumes that $k$ is characteristic 0. We have a $k$-bilinear pairing 
$$
\D(W) \times k[W] \to k
$$
by $\<u,f\>\mapsto u(f)(0)$. This is a \textit{perfect pairing}. And in general we can do the same thing with 
$$
\Sym^j(W)\times \Sym^j(W^*)\to k.
$$

\noindent \textbf{Lemma}: Let $\xi\in W$ and $f\in k[W]$. Then
$$\<\xi^m,f\> = m!f(\xi).$$
In particular, if $f=\ph\in W^*$, $\<\xi^m,\ph^m\>=m!\ph^m(\xi)$.
\begin{proof}
	We will show this for homogeneous $f$ first, and the general result will follow from expressing $f$ as a sum of homogeneous polynomials. Let the degree of $f$ be $d$. Then by Taylor expansion,
	$$f(\xi) = \sum_{k\geq 0} \frac{1}{k!}(\partial_{\xi}^kf)(0).$$
	But note that only the $d$th term of this is nonzero, since $\partial^j_{\xi}f= 0$ unless $j=d$ (since we are evaluating at $0$). Thus,
	$$
	f(\xi) = \frac{(\partial^d_{\xi}f)(0)}{d!}
	$$
	and for other $j$ both sides are 0.
\end{proof}\\

We can use this pairing to get another inner product on polynomials in $k[W]$ given by
$$
\<p,q\> := p(\partial)(q)(0)
$$
where $p(\partial)$ is the corresponding element to $p$ in $\D(W)$.\footnote{In the homework, we establish that on $H_d$, this is actually \textit{equivalent} to the inner product from integrating over $S^{n-1}$!} For this inner product, we have that multiplication by $p$ is \textit{adjoint} to $p(\partial)$, i.e.
$$
\<r,p(\partial)q\> = \<pr,q\>.
$$
With this fact, we can finally show why $P_d = H_d \oplus R P_{d-2}$:
$$
W = \ker(\Delta) \oplus \im(\Delta^*) = \ker(\Delta) \oplus \im(R) = H_d \oplus R P_{d-2}.
$$

Another application of this pairing:
Let $V$ be a finite dimensional vector space and $A\subseteq V$ a subset of $V$ (not necessarily subspace).
Let $\Span^d(A)\subseteq \Sym^d(V)$ be generated over $\C$ by $a^d$ for $a\in A$.
If $A$ is dense in $V$ then $\Span^d(A) = \Sym^d(A)$. 
We will show this by using the pairing.

Assume for contradiction that $\Span^d(A)\neq \Sym^d(V)$. 
Then there is some nonzero linear functional $F:\Sym^d(V)\to \C$ which vanishes on $\Span^d(A)$. 
Then $F$ corresponds to some differential polynomial $f$, and $\partial^d_a f(0) = 0$ for all $a\in A$.
But $\partial^d_af(0) = d!f(a)$, so $f(a)=0$. But then $A$ is dense, so $f=0$.\\

\subsection{Representation Theory Basics}
 
If $G$ acts on sets $X$ and $Y$, then $G$ can also act on the space of maps $X\to Y$ via conjugation:
$$
g: f \mapsto g\circ f \circ g^{-1}.
$$
We can ask about the space of maps which commute with this $G$-action. Or, equivalently, the maps which are fixed by the $G$-action. 
We call these \textit{intertwining operators}. 
The set of such operators is denoted $\Hom_G(X,Y)$. 

We are usually interested in the case where $X,Y$ are vector spaces and $\Hom(X,Y)$ is the space of linear maps.\\

\noindent \textbf{Schur-Weyl Duality}: 
Let $W$ be a finite-dimensional vector space over $\C$.
$\GL(W)$ can act on $W^{\otimes d}$ with $g$ acting as $g^{\otimes d}$.
$S_d$ also acts on $W^{\otimes d}$ by permutation.
It is not too hard to see that these two actions commute.
But moreover, action by $\GL(W)$ \textit{spans} the space of $S_d$-intertwiners on $W^{\otimes d}$.

\begin{proof}
	Let $\Phi:(\End(W))^{\otimes d}\to \End(W^{\otimes d})$ be given by
	$$
	\Phi: a_1\otimes \cdots \otimes a_d \mapsto \big(w_1\otimes \cdots \otimes w_d \mapsto a_1(w_1)\otimes \cdots \otimes a_d(w_d)\big).
	$$
	$\Phi$ is an invertible linear map with inverse
	$$
	\Phi^{-1} f \mapsto f|_{W_1}\otimes \cdots \otimes f|_{W_d}
	$$ 
	where $W_j$ is $0 \otimes \cdots \otimes W \otimes \cdots \otimes 0$ with the $W$ in the $j$th spot.
	Note also that $\Phi$ commutes with the action of $S_d$. By using $\Phi$, we see that 
	$$
	\Sym^d(\End W) = ((\End W)^{\otimes d})^{S_d} \xrightarrow{\Phi^{-1}} \End_{S_d}(W^{\otimes d}).
	$$
	So we only need to understand $\Sym^d(\End W)$. But $\GL(W)$ is dense in $\End(W)$, so by a previous lemma, we see that $\Span^d(\GL(W))=\Sym^d(\End W)$.
\end{proof}\\

\subsection{Spectral Theorem}

Let $A$ be a $k$-algebra with $a\in A$. We have an evaluation map
$$
\ev_a : k[t] \to A \;\;\; \ev_a: p\mapsto p(a).
$$
Let $A_a:= \im(\ev_a)$, i.e. the subalgebra of $A$ generated by $a$. The kernel $\ker(\ev_a)$ is an ideal of $k[t]$, and it is a principal ideal since $k[t]$ is a PID. Thus, in the case that $\ev_a$ is non-injective, there is a unique \textit{minimal polynomial} of $a$, $p_a$, which divides every polynomial which vanishes at $a$.\\

\noindent \textbf{Lemma}: $a$ is algebraic iff $A_a$ is finite-dimensional.
\begin{proof}
	If $A_a$ is finite-dimensional then there is a relation between $1,a,a^2,\dots,a^n$ for some $n$, i.e. a polynomial that $a$ solves. Conversely if $a$ solves a polynomial of degree $n$ then every linear combination of powers of $a$ can be expressed by the first $n$ powers of $a$.
\end{proof}\\

We define the \textit{spectrum} of $a$, denoted $\Spec(a)$, as
$$
\Spec(a) := \{\lambda \in k : (a-\lambda) \text{ is not invertible}\}.
$$
So for example, if $A$ is a function algebra, $\Spec(a)$ denotes the values that $a$ can take. In the case that $A$ is the matrix algebra $M_n(k)$, $\Spec(a)$ is the set of eigenvalues of $a$.\\

\textbf{The Spectral Theorem}: Let $A$ be a $k$-algebra of one of the following types:
\begin{itemize}
	\item $A$ is finite-dimensional over $k$ and $k$ is algebraically closed.
	\item $A$ is countable-dimension and $k$ is uncountable.
\end{itemize}
Then,
\begin{enumerate}[(i)]
	\item $\Spec(a)$ is nonempty.
	\item $a$ is nilpotent iff $\Spec(a)=\{0\}$.
	\item If $A$ is a division algebra then $A=k$.\footnote{For a counterexample of this when $k$ is not algebraically closed, take the Quaternions over $\R$.}
\end{enumerate}
\begin{proof}
	Lemma: If $\lambda_1,\dots\lambda_n\not\in \Spec(a)$, i.e. $(a-\lambda_j)$ is invertible for each $j$, then if 
	$$
	\sum_j c_j(a-\lambda_j)^{-1} = 0
	$$
	for some $c_j\in k$ then $a$ is algebraic (proof is by clearing denominators). We will use this fact.\\
	
	(i): We will split into two cases: if $a$ is algebraic then $\Spec(a)$ is finite but nonempty and if $a$ is not algebraic then $\Spec(a)$ is uncountable (and the converses to both of these are true).
	
	If $a$ is algebraic, then $\Spec(a)$ is the roots of the minimal polynomial (HW), and particular this means $\Spec(a)$ is finite and nonempty because $k$ is algebraically closed.
	
	If $a$ is not algebraic, then by the Lemma, there is no linear relation between any finitely-many $(a-\lambda)^{-1}$ for $\lambda\not\in \Spec(a)$. We assumed that $\dim(A)$ is at most countable, and it has an independent set of size $|k\setminus \Spec(a)|$, so $\Spec(a)$ must be uncountable (because $k$ is).\\
	
	(iii): Assume for contradiction that $A$ is a division algebra yet $\exists a\in A\setminus k$. Then $(a-\lambda)$ is invertible for all $\lambda \in k$, but then $\Spec(a)$ would be empty, contradicting (i).
\end{proof}



\end{document}